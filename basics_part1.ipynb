{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing softmax regression with tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data handler included in TF examples (downloads data)\n",
    "mnist = input_data.read_data_sets('../data/mnist', one_hot=True)\n",
    "#####################################\n",
    "###    logistic regression model ####\n",
    "###       pred = logsig(W*x + b) ####\n",
    "#####################################\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create loss to train\n",
    "label = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "# Use combined logsig and xent to have numerically stable gradients\n",
    "xent_cost = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(xent_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training cost 2.30259, training accuracy 0.05\n",
      "step 100, training cost 0.375479, training accuracy 0.89\n",
      "step 200, training cost 0.318712, training accuracy 0.92\n",
      "step 300, training cost 0.368025, training accuracy 0.9\n",
      "step 400, training cost 0.54925, training accuracy 0.84\n",
      "step 500, training cost 0.31254, training accuracy 0.92\n",
      "step 600, training cost 0.234687, training accuracy 0.95\n",
      "step 700, training cost 0.296957, training accuracy 0.92\n",
      "step 800, training cost 0.549686, training accuracy 0.85\n",
      "step 900, training cost 0.330141, training accuracy 0.93\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    ## display training accuracy \n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch_xs, label: batch_ys})\n",
    "        train_cost = xent_cost.eval(feed_dict={\n",
    "        x:batch_xs, label: batch_ys})\n",
    "        print(\"step %d, training cost %g, training accuracy %g\"%(i, train_cost, train_accuracy))\n",
    "    ## \n",
    "    sess.run(train_step, feed_dict={x: batch_xs, label: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9201\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      label: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
